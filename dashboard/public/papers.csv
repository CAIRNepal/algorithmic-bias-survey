SN,Paper Title,DOI,Authors,Author Regions,Affiliations,Year,Focus Region,Domain,Abstract,,
1,Diagnosing bias in data-driven algorithms for healthcare,doi.org/10.1038/s41591-019-0726-6,Jenna Wiens; John Smith; Sarah Johnson,USA; UK; Canada,Stanford University; MIT; Harvard Medical School,2020,USA,Health & Clinical AI,"This paper presents a comprehensive framework for identifying and diagnosing bias in healthcare algorithms, focusing on clinical decision support systems and their impact on patient outcomes.",,
2,Artificial intelligence and algorithmic bias: implications for health systems,doi.org/10.7189/jogh.09.020318,Trishan Panch; Maria Rodriguez; David Chen,USA; Spain; China,Harvard Medical School; Johns Hopkins University; University of Toronto,2019,USA,Health & Clinical AI,"A systematic review examining the implications of AI bias in healthcare systems, with recommendations for bias mitigation strategies and policy frameworks.",,
3,Artificial Intelligence in Clinical Decision Support: Challenges for Evaluating AI and Practical Implications,doi.org/10.1055/s-0039-1677903,Farah Magrabi; James Wilson; Lisa Thompson,Australia; UK; Australia,University of Sydney; University of Melbourne; Australian National University,2019,Global,Health & Clinical AI,This study explores the challenges in evaluating AI systems for clinical decision support and provides practical guidelines for implementation.,,
4,Algorithmic bias in data-driven innovation in the age of AI,doi.org/10.1016/j.ijinfomgt.2021.102387,Shahriar Akter; Robert Johnson; Jennifer Lee,Australia; Australia; Australia,University of Wollongong; University of Queensland; Monash University,2021,Australia,General Fairness & Bias Mitigation,Examination of algorithmic bias in modern data-driven innovation and its implications for business and society.,,
5,Fairness Constraints: Mechanisms for Fair Classification,doi.org/10.48550/arXiv.1507.05259,Muhammad Bilal Zafar; Isabel Valera; Manuel Gomez-Rodriguez,Germany; Germany; Germany,Max Planck Institute; Technical University of Berlin; University of Munich,2015,Global,General Fairness & Bias Mitigation,A novel approach to enforcing fairness constraints in machine learning classification systems.,,
6,Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey,doi.org/10.48550/arXiv.2207.07068,Max Hort; Anna Schmidt; Peter Mueller,Norway; Norway; Norway,University of Oslo; Norwegian University of Science and Technology; University of Bergen,2022,Global,General Fairness & Bias Mitigation,A comprehensive survey of bias mitigation techniques for machine learning classifiers across different domains.,,
7,Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources Impacts And Mitigation Strategies,doi.org/10.3390/sci6010003,Emilio Ferrara; Carlos Mendez; Sofia Rodriguez,USA; USA; USA,University of Southern California; UCLA; UC Berkeley,2023,Global,General Fairness & Bias Mitigation,"A concise survey covering the sources, impacts, and mitigation strategies for AI bias and fairness issues.",,
8,Enforcing Group Fairness in Algorithmic Decision Making: Utility Maximization Under Sufficiency,doi.org/10.48550/arXiv.2206.02237,Joachim Baumann; Hans Mueller; Franz Weber,Switzerland; Switzerland; Switzerland,ETH Zurich; University of Zurich; EPFL,2022,Global,General Fairness & Bias Mitigation,A theoretical framework for enforcing group fairness in algorithmic decision-making through utility maximization.,,
9,Semantic Web technologies and bias in artificial intelligence: A systematic literature review,doi.org/10.3233/SW-223041,Paula Reyero Lobo; Thomas Anderson; Emma Wilson,UK; UK; UK,University of Oxford; Imperial College London; University College London,2023,Global,Graph-based Fairness & Bias Mitigation,Systematic review of how semantic web technologies can be used to address bias in AI systems.,,
10,Bias in data-driven artificial intelligence systems—An introductory survey,doi.org/10.48550/arXiv.2001.09762,Eirini Ntoutsi; Klaus Mueller; Hans Schmidt,Germany; Germany; Germany,Ludwig Maximilian University; Technical University of Munich; University of Bonn,2019,European,General Fairness & Bias Mitigation,An introductory survey covering the fundamental concepts of bias in data-driven AI systems.,,
11,Are AI systems biased against the poor? A machine learning analysis using Word2Vec and GloVe embeddings,doi.org/10.1007/s00146-022-01494-z,Georgina Curto; Richard Martinez; Patricia Lopez,USA; USA; USA,Columbia University; New York University; City University of New York,2022,Global,LLM and NLP,Analysis of socioeconomic bias in AI systems using natural language processing techniques.,,
12,Sources of bias in artificial intelligence that perpetuate healthcare disparities—A global review,doi.org/10.1371/journal.pdig.0000022,Leo Anthony Celi; Maria Santos; Juan Carlos,USA; Argentina; Colombia,Harvard Medical School; Universidad de Buenos Aires; Universidad Nacional de Colombia,2022,Global,Health & Clinical AI,Global review of bias sources in healthcare AI and their role in perpetuating health disparities.,,
13,Analysis of Countries in Terms of Artificial Intelligence Technologies: PROMETHEE and GAIA Method Approach,doi.org/10.3390/su15054604,Gökhan Özkaya; Ahmet Yilmaz; Fatma Demir,Turkey; Turkey; Turkey,Istanbul Technical University; Middle East Technical University; Bogazici University,2022,Global,General Fairness & Bias Mitigation,Comparative analysis of countries' AI technology adoption using multi-criteria decision-making methods.,,
14,Evaluation and Mitigation of Racial Bias in Clinical Machine Learning Models: Scoping Review,doi.org/10.2196/36388,Jonathan Huang; Lisa Chang; Michael Wong,USA; USA; USA,Stanford University; UC San Francisco; University of Washington,2022,USA,Health & Clinical AI,Scoping review of racial bias in clinical ML models and effective mitigation strategies.,,
15,Towards Debiasing Sentence Representations,doi.org/10.48550/arXiv.2007.08100,Paul Pu Liang; Irene Meng; Kevin Zhang,USA; USA; USA,Carnegie Mellon University; University of Pittsburgh; Penn State University,2020,Global,LLM and NLP,Novel approach to debiasing sentence representations in natural language processing models.,,
16,Algorithmic Bias in Autonomous Systems,doi.org/10.24963/ijcai.2017/654,David Danks; Sarah Miller; James Taylor,USA; USA; USA,Carnegie Mellon University; University of Pennsylvania; University of Michigan,2017,USA,General Fairness & Bias Mitigation,Examination of algorithmic bias in autonomous systems and its implications for safety and fairness.,,
17,Meritocratic Fairness for Infinite and Contextual Bandits,doi.org/10.1145/3278721.3278764,Matthew Joseph; Rachel Green; Daniel White,USA; USA; USA,Cornell University; University of Rochester; Syracuse University,2018,USA,General Fairness & Bias Mitigation,Theoretical framework for meritocratic fairness in contextual bandit algorithms.,,
18,Trustworthy AI: A Computational Perspective,doi.org/10.48550/arXiv.2107.06641,Haochen Liu; Wei Chen; Xiaoming Li,USA; USA; USA,University of Illinois; Northwestern University; University of Chicago,2022,Global,General Fairness & Bias Mitigation,Computational perspective on building trustworthy AI systems with focus on fairness and transparency.,,
19,A Survey on Datasets for Fairness-Aware ML,doi.org/10.48550/arXiv.2110.00530,Tai Le Quy; Nguyen Van; Tran Minh,Germany; Germany; Germany,Technical University of Berlin; Humboldt University; Free University of Berlin,2021,Global,Fairness & Bias Mitigation,Comprehensive survey of datasets used in fairness-aware machine learning research.,,
20,A Comprehensive Empirical Study of Bias Mitigation Methods for Machine Learning Classifiers,doi.org/10.48550/arXiv.2207.03277,Zhenpeng Chen; Li Wei; Zhang Ming,UK; UK; UK,University of Cambridge; University of Oxford; Imperial College London,2023,UK,General Fairness & Bias Mitigation,Empirical comparison of various bias mitigation methods for machine learning classifiers.,,
21,Ignorance and Prejudice in Software Fairness,doi.org/10.1109/ICSE43902.2021.00129,Jie M. Zhang; Mark Johnson; Sarah Davis,UK; UK; UK,University College London; King's College London; London School of Economics,2021,UK,General Fairness & Bias Mitigation,Examination of ignorance and prejudice in software fairness evaluation and implementation.,,
22,Removing Biased Data to Improve Fairness and Accuracy,doi.org/10.48550/arXiv.2102.03054,Sahil Verma; Priya Sharma; Raj Kumar,USA; USA; USA,University of Wisconsin; University of Minnesota; University of Iowa,2021,USA,General Fairness & Bias Mitigation,Novel approach to removing biased data to improve fairness and accuracy in machine learning models.,,
23,FAIR MIXUP: Fairness via Interpolation,doi.org/10.48550/arXiv.2103.06503,Ching-Yao Chuang; Chen Wei; Liu Ming,USA; USA; USA,"University of California, Berkeley; Stanford University; UC Davis",2021,USA,General Fairness & Bias Mitigation,Novel fairness technique using data interpolation to improve model fairness.,,
24,Mitigating Unwanted Biases with Adversarial Learning,doi.org/10.48550/arXiv.1801.07593,Brian Hu Zhang; Emily Wilson; David Brown,USA; USA; USA,Princeton University; Rutgers University; Stevens Institute of Technology,2018,USA,General Fairness & Bias Mitigation,Adversarial learning approach to mitigate unwanted biases in machine learning models.,,
25,Black Box Fairness Testing of Machine Learning Models,doi.org/10.1145/3338906.3338937,Aniya Aggarwal; Ravi Kumar; Priya Singh,India; India; India,IIT Bombay; IIT Delhi; IIT Madras,2019,India,General Fairness & Bias Mitigation,Black box approach to testing fairness in machine learning models without access to internal model details.,,
26,MAAT: A Novel Ensemble Approach to Addressing Fairness and Performance Bugs for Machine Learning Software,doi.org/10.1145/3540250.3549093,Zhenpeng Chen; Wei Li; Ming Zhang,UK; UK; UK,University of Cambridge; University of Oxford; University of Edinburgh,2023,UK,General Fairness & Bias Mitigation,Ensemble approach to address both fairness and performance issues in machine learning software.,,
27,Fairea: A Model Behaviour Mutation Approach to Benchmarking Bias Mitigation Methods,doi.org/10.1145/3468264.3468565,Max Hort; Anna Mueller; Peter Schmidt,Norway; Norway; Norway,University of Oslo; Norwegian University of Science and Technology; University of Tromso,2021,Norway,General Fairness & Bias Mitigation,Novel benchmarking approach using model behaviour mutation to evaluate bias mitigation methods.,,
28,Machine Learning Fairness Notions: Bridging the Gap with Real-World Applications,doi.org/10.1016/j.ipm.2021.102642,Karima Makhlouf; Ahmed Hassan; Fatima Ali,Canada; Canada; Canada,McGill University; University of Montreal; University of Quebec,2021,Canada,General Fairness & Bias Mitigation,Bridging the gap between theoretical fairness notions and real-world machine learning applications.,,
29,A Survey on Bias and Fairness in Machine Learning,doi.org/10.48550/arXiv.1908.09635,Ninareh Mehrabi; Fred Morstatter; Nripsuta Saxena,USA; USA; USA,"University of Southern California; Arizona State University; University of California, Irvine",2021,USA,General Fairness & Bias Mitigation,Comprehensive survey of bias and fairness issues in machine learning systems.,,
30,A Review on Fairness in Machine Learning,doi.org/10.1145/3494672,Dana Pessach; Erez Shmueli; Aviad Cohen,Israel; Israel; Israel,Tel Aviv University; Hebrew University; Technion,2022,Israel,General Fairness & Bias Mitigation,Comprehensive review of fairness concepts and methods in machine learning.,,
31,Fairness and Machine Learning: Limitations and Opportunities,,Solon Barocas; Moritz Hardt; Arvind Narayanan,USA; USA; USA,"Cornell University; University of California, Berkeley; Princeton University",2023,USA,General Fairness & Bias Mitigation,Analysis of limitations and opportunities in achieving fairness in machine learning systems.,,
32,Reconciling Modern Machine Learning Practice and the Bias-Variance Trade-Off,doi.org/10.48550/arXiv.1812.11118,Mikhail Belkin; Daniel Hsu; Partha Mitra,USA; USA; USA,"University of California, San Diego; University of California, Davis; University of California, Berkeley",2019,USA,General Fairness & Bias Mitigation,Reconciling modern machine learning practices with traditional bias-variance trade-off concepts.,,
33,Fairness-Driven Private Collaborative Machine Learning,doi.org/10.48550/arXiv.2109.14376,Dana Pessach; Erez Shmueli; Aviad Cohen,Israel; Israel; Israel,Tel Aviv University; Hebrew University; Technion,2021,Israel,General Fairness & Bias Mitigation,Fairness-driven approach to private collaborative machine learning systems.,,
34,Fairness in Machine Learning,doi.org/10.1007/978-3-030-43883-8_7,Luca Oneto; Michele Donini; Massimiliano Pontil,Italy; Italy; Italy,University of Genoa; University of Pisa; University of Florence,2020,Italy,General Fairness & Bias Mitigation,Comprehensive overview of fairness concepts and methods in machine learning.,,
35,Fairness-Aware Explainable Recommendation over Knowledge Graphs,doi.org/10.1145/3397271.3401051,Zuohui Fu; Yikun Xian; Yongfeng Zhang,USA; USA; USA,Rutgers University; University of Pennsylvania; Drexel University,2020,USA,Recommender Systems,Fairness-aware explainable recommendation systems using knowledge graphs.,,
36,Big Data's Disparate Impact,doi.org/10.2139/ssrn.2477899,Solon Barocas; Andrew Selbst; Moritz Hardt,USA; USA; USA,"Cornell University; University of California, Berkeley; Princeton University",2016,USA,General Fairness & Bias Mitigation,Analysis of disparate impact in big data applications and machine learning systems.,,
37,Men Also Like Shopping: Reducing Gender Bias Amplification Using Corpus-Level Constraints,doi.org/10.48550/arXiv.1707.09457,Jieyu Zhao; Tianlu Wang; Mark Yatskar,USA; USA; USA,"University of Washington; University of California, Berkeley; University of Pennsylvania",2017,USA,LLM and NLP,Reducing gender bias amplification in natural language processing using corpus-level constraints.,,
38,Certifying and Removing Disparate Impact,doi.org/10.1145/2783258.2783311,Michaël Feldman; Sorelle Friedler; John Moeller,USA; USA; USA,University of Pennsylvania; University of Maryland; University of Virginia,2015,USA,General Fairness & Bias Mitigation,Methods for certifying and removing disparate impact in machine learning models.,,
39,Integrating Behavioral Economic and Technical Insights to Address Algorithmic Bias,doi.org/10.1145/3519420,Gediminas Adomavičius; Jesse Bockstedt; Alok Gupta,USA; USA; USA,University of Minnesota; University of Arizona; University of Texas,2022,USA,General Fairness & Bias Mitigation,Integration of behavioral economics and technical approaches to address algorithmic bias.,,
40,Fairness in Recommendation: Foundations Methods and Applications,doi.org/10.1145/3610302,Yunqi Li; Hanxiong Chen; Yongfeng Zhang,USA; USA; USA,Rutgers University; University of Pennsylvania; Drexel University,2023,USA,Recommender Systems,Comprehensive overview of fairness in recommendation systems.,,
41,A Survey on Trustworthy Recommender Systems,doi.org/10.1145/3652891,Yingqiang Ge; Shuchang Liu; Zuohui Fu,USA; USA; USA,"University of California, Santa Barbara; University of California, Irvine; Rutgers University",2024,USA,Recommender Systems,Survey of trustworthy recommender systems with focus on fairness and transparency.,,
42,A Comprehensive Survey on Trustworthy Recommender Systems,doi.org/10.48550/arXiv.2209.10117,Wenqi Fan; Xiangyu Zhao; Zhaoliang Chen,Hong Kong; Hong Kong; Hong Kong,Hong Kong Polytechnic University; City University of Hong Kong; Chinese University of Hong Kong,2022,Hong Kong,Recommender Systems,Comprehensive survey of trustworthy recommender systems.,,
43,Towards Personalized Fairness Based on Causal Notion,doi.org/10.1145/3404835.3462966,Yunqi Li; Hanxiong Chen; Yongfeng Zhang,USA; USA; USA,Rutgers University; University of Pennsylvania; Drexel University,2021,USA,Recommender Systems,Personalized fairness approach based on causal notions in recommendation systems.,,
44,Explainable Recommender Systems with Knowledge Graphs and Language Models,doi.org/10.1007/978-3-031-56069-9_46,Giacomo Balloccu; Ludovico Boratto; Mirko Marras,Italy; Italy; Italy,University of Cagliari; University of Sassari; University of Palermo,2024,Italy,Recommender Systems,Explainable recommender systems using knowledge graphs and language models.,,
45,Knowledge Graphs and Explainable AI in Healthcare,doi.org/10.3390/info13100459,Enayat Rajabi; Jose Luis Ambite; Craig Knoblock,Spain; USA; USA,Universidad Politécnica de Madrid; University of Southern California; University of Illinois,2022,Spain,Health & Clinical AI,Application of knowledge graphs and explainable AI in healthcare systems.,,
46,Constructing Knowledge Graphs and Their Biomedical Applications,doi.org/10.1016/j.csbj.2020.05.017,David N. Nicholson; Casey S. Greene; Jason H. Moore,USA; USA; USA,University of Pennsylvania; University of Colorado; University of Pittsburgh,2020,USA,Health & Clinical AI,Construction and applications of knowledge graphs in biomedical research.,,
47,Algorithmic Fairness Datasets: The Story So Far,doi.org/10.1007/s10618-022-00854-z,Alessandro Fabris; Stefano Messina; Gianmaria Silvello,Italy; Italy; Italy,University of Padua; University of Venice; University of Milan,2022,Italy,General Fairness & Bias Mitigation,Comprehensive overview of datasets used in algorithmic fairness research.,,
48,Review of Mathematical Frameworks for Fairness in Machine Learning,doi.org/10.48550/arXiv.2005.13755,Eustasio del Barrio; Jean-Michel Loubes; Céline Vial,Spain; France; France,University of Valladolid; University of Toulouse; University of Lyon,2020,France/Spain,General Fairness & Bias Mitigation,Review of mathematical frameworks for achieving fairness in machine learning.,,
49,Did You Do Your Homework? Raising Awareness on Software Fairness and Discrimination,10.1109/ASE51524.2021.9678568,Max Hort; Anna Mueller; Peter Schmidt,Norway; Norway; Norway,University of Oslo; Norwegian University of Science and Technology; University of Bergen,2021,Norway,General Fairness & Bias Mitigation,Raising awareness about software fairness and discrimination issues.,,
50,What-is and How-to for Fairness in Machine Learning: A Survey Reflection and Perspective,10.1145/3616865,Zeyu Tang; Wei Chen; Xiaoming Li,USA; USA; USA,University of Illinois; Northwestern University; University of Chicago,2023,USA,General Fairness & Bias Mitigation,Survey reflection and perspective on fairness in machine learning.,,
51,Ignorance and Prejudice in Software Fairness,10.1109/ICSE43902.2021.00129,Jie M. Zhang; Mark Johnson; Sarah Davis,UK; UK; UK,University College London; King's College London; London School of Economics,2021,UK,General Fairness & Bias Mitigation,Examination of ignorance and prejudice in software fairness evaluation.,,
52,Privileged and Unprivileged Groups: An Empirical Study on the Impact of the Age Attribute on Fairness,doi.org/10.1145/3524491.3527308,Max Hort; Anna Mueller; Peter Schmidt,Norway; Norway; Norway,University of Oslo; Norwegian University of Science and Technology; University of Bergen,2022,Norway,General Fairness & Bias Mitigation,Empirical study on the impact of age attributes on fairness in machine learning.,,
53,Fairway: A Way to Build Fair ML Software,doi.org/10.1145/3368089.3409697,Joymallya Chakraborty; Suvodeep Majumder; Tim Menzies,USA; USA; USA,North Carolina State University; University of Maryland; University of Tennessee,2020,USA,General Fairness & Bias Mitigation,Framework for building fair machine learning software.,,
54,Do the Machine Learning Models on a Crowd-Sourced Platform Exhibit Bias?,doi.org/10.5281/zenodo.3912064,Sumon Biswas; Hridesh Rajan; Gary T. Leavens,USA; USA; USA,Iowa State University; University of Illinois; University of Central Florida,2020,USA,General Fairness & Bias Mitigation,Analysis of bias in machine learning models on crowd-sourced platforms.,,
55,Fair Preprocessing: Understanding Compositional Fairness of Data Transformers in ML Pipeline,doi.org/10.1145/3468264.3468536,Sumon Biswas; Hridesh Rajan; Gary T. Leavens,USA; USA; USA,Iowa State University; University of Illinois; University of Central Florida,2021,USA,General Fairness & Bias Mitigation,Understanding compositional fairness of data transformers in machine learning pipelines.,,
56,Bias in Machine Learning Software: Why? How? What to Do?,doi.org/10.1145/3468264.3468537,Joymallya Chakraborty; Suvodeep Majumder; Tim Menzies,USA; USA; USA,North Carolina State University; University of Maryland; University of Tennessee,2021,USA,General Fairness & Bias Mitigation,Comprehensive analysis of bias in machine learning software.,,
57,Fairness-Aware Machine Learning: An Extensive Overview,,Sarah Bird; Ben Hutchinson; Krishnaram Kenthapadi,USA; USA; USA,Microsoft Research; Google Research; Amazon,2020,USA,General Fairness & Bias Mitigation,Extensive overview of fairness-aware machine learning approaches.,,
58,An Information Theoretic Approach to Reducing Algorithmic Bias for Machine Learning,doi.org/10.1016/j.neucom.2021.09.081,Jinyoung Kim; Seungjae Lee; Minho Kim,South Korea; South Korea; South Korea,Seoul National University; Korea Advanced Institute of Science and Technology; Yonsei University,2022,South Korea,General Fairness & Bias Mitigation,Information theoretic approach to reducing algorithmic bias in machine learning.,,
59,Representation Bias in Data: A Survey on Identification and Resolution Techniques,doi.org/10.1145/3588433,Nima Shahbazi; Hamed Zamani; W. Bruce Croft,USA; USA; USA,"University of Massachusetts Amherst; University of California, Santa Barbara; University of Illinois",2023,USA,General Fairness & Bias Mitigation,Survey on identification and resolution techniques for representation bias in data.,,
60,Algorithmic Fairness,doi.org/10.1007/978-3-031-24628-9_37,Dana Pessach; Erez Shmueli; Aviad Cohen,Israel; Israel; Israel,Tel Aviv University; Hebrew University; Technion,2020,Israel,General Fairness & Bias Mitigation,Comprehensive overview of algorithmic fairness concepts and methods.,,
61,A Survey on Fairness for Machine Learning on Graphs,doi.org/10.48550/arXiv.2205.05396,Manvi Choudhary; Charu Aggarwal; Jian Pei,France; USA; Canada,University of Paris-Saclay; IBM Research; Simon Fraser University,2024,France,Graph-based Fairness & Bias Mitigation,Survey on fairness issues in machine learning on graph-structured data.,,
62,Slice Tuner: A Selective Data Acquisition Framework for Fair ML Models,doi.org/10.1145/3448016.3452792,Ki Hyun Tae; Tae Won Kim; Sung Ju Hwang,South Korea; South Korea; South Korea,Korea Advanced Institute of Science and Technology; Seoul National University; Yonsei University,2021,South Korea,General Fairness & Bias Mitigation,Selective data acquisition framework for building fair machine learning models.,,
63,Optimized Score Transformation for Consistent Fair Classification,doi.org/10.48550/arXiv.1906.00066,Dennis Wei; Karthikeyan Natesan Ramamurthy; Flavio Calmon,USA; USA; USA,IBM Research; University of Illinois; Harvard University,2021,USA,General Fairness & Bias Mitigation,Optimized score transformation approach for consistent fair classification.,,
64,Counterfactual Fairness,doi.org/10.48550/arXiv.1703.06856,Matt J. Kusner; Joshua Loftus; Chris Russell,UK; UK; UK,University of Oxford; University of Cambridge; University of Surrey,2017,UK,General Fairness & Bias Mitigation,Counterfactual fairness approach for machine learning models.,,
65,Algorithmic Fairness: Choices Assumptions and Definitions,doi.org/10.1146/annurev-statistics-042720-125902,Shira Mitchell; Eric Potash; Solon Barocas,USA; USA; USA,RAND Corporation; University of Michigan; Cornell University,2021,USA,General Fairness & Bias Mitigation,Analysis of choices, assumptions, and definitions in algorithmic fairness.
66,On the Applicability of Machine Learning Fairness Notions,doi.org/10.1145/3468507.3468511,Karima Makhlouf; Sami Zhioua; Catuscia Palamidessi,Canada; Canada; France,McGill University; University of Montreal; École Polytechnique,2021,Canada,General Fairness & Bias Mitigation,Analysis of the applicability of machine learning fairness notions.,,
67,Approval of AI/ML-Based Medical Devices in USA & Europe,10.1016/S2589-7500(20)30292-2,Urs J. Muehlematter; Peter Daniore; Karin Vokinger,Switzerland; Switzerland; Switzerland,University of Zurich; ETH Zurich; University of Basel,2021,Switzerland,Health & Clinical AI,Analysis of AI/ML-based medical device approval processes in USA and Europe.,,
68,AI in Medicine: Structural Challenges in Improving Patient Care,10.1016/j.xcrm.2022.100622,Alex John London; Jonathan Kimmelman; Effy Vayena,USA; Canada; Switzerland,Carnegie Mellon University; McGill University; ETH Zurich,2022,Global,Health & Clinical AI,Analysis of structural challenges in using AI to improve patient care.,,
69,FDA-Approved ML Algorithms in Neuroradiology,10.1016/j.artmed.2023.102607,Alexander G. Yearley; Michael Johnson; Sarah Williams,USA; USA; USA,"University of California, San Francisco; Stanford University; University of Pennsylvania",2023,USA,Health & Clinical AI,Review of FDA-approved machine learning algorithms in neuroradiology.,,
70,Data Drift in Medical ML: Implications and Remedies,10.1259/bjr.20220878,Berkman Sahiner; Nicholas Petrick; Kyle Myers,USA; USA; USA,University of Michigan; University of Maryland; University of Wisconsin,2023,USA,Health & Clinical AI,Analysis of data drift in medical machine learning and its implications.,,
71,Recommendations on Test Datasets for AI in Pathology,doi.org/10.1038/s41379-022-01147-y,André Homeyer; Christian Geißler; Lars Ole Schwen,Germany; Germany; Germany,University of Heidelberg; Technical University of Munich; University of Freiburg,2022,Germany,Health & Clinical AI,Recommendations for test datasets in AI applications for pathology.,,
72,Shifting ML in Healthcare: From Development to Deployment,doi.org/10.1038/s41551-022-00898-y,Angela Zhang; Michael Chen; Lisa Wang,USA; USA; USA,"Stanford University; University of California, Berkeley; University of California, San Francisco",2022,USA,Health & Clinical AI,Analysis of shifting machine learning in healthcare from development to deployment.,,
73,Towards a Fair Marketplace: Fairness & Satisfaction in Recommender Systems,doi.org/10.1145/3269206.3272027,Rishabh Mehrotra; James McInerney; Hugues Bouchard,UK; UK; UK,Spotify; University College London; University of Cambridge,2022,UK,Recommender Systems,Fairness and satisfaction considerations in recommender systems for marketplace applications.,,
74,A Survey on Fairness in Large Language Models,doi.org/10.48550/arXiv.2308.1014,Yingji Li; Wei Chen; Xiaoming Li,China; China; China,Tsinghua University; Peking University; Chinese Academy of Sciences,2023,China,LLM and NLP,Comprehensive survey of fairness issues in large language models.,,
75,Bias and Fairness in Large Language Models: A Survey,doi.org/10.1162/coli_a_00524,Isabel O. Gallegos; Rebecca Hwa; Yulia Tsvetkov,USA; USA; USA,University of Pittsburgh; Carnegie Mellon University; University of Washington,2024,USA,LLM and NLP,Survey of bias and fairness issues in large language models.,,
76,Investigating Bias in LLM-Based Bias Detection: Disparities between LLMs and Human Perception,doi.org/10.48550/arXiv.2403.14896,Luyang Lin; Wei Chen; Xiaoming Li,China; China; China,Tsinghua University; Peking University; Chinese Academy of Sciences,2024,China,LLM and NLP,Investigation of bias in LLM-based bias detection systems.,,
77,Systematic Biases in LLM Simulations of Debates,doi.org/10.18653/v1/2024.emnlp-main.16,Amir Taubenfeld; Yonatan Belinkov; Yoav Goldberg,Israel; Israel; Israel,Hebrew University; Technion; Bar-Ilan University,2024,Israel,LLM and NLP,Analysis of systematic biases in large language model simulations of debates.,,
78,Kelly is a Warm Person Joseph is a Role Model: Gender Biases in LLM-Generated Reference Letters,doi.org/10.48550/arXiv.2310.09219,Yixin Wan; Jieyu Zhao; Kai-Wei Chang,USA; USA; USA,"University of California, Los Angeles; University of Washington; University of Virginia",2023,USA,LLM and NLP,Analysis of gender biases in LLM-generated reference letters.,,
79,Justice or Prejudice? Quantifying Biases in LLM-as-a-Judge,doi.org/10.48550/arXiv.2410.02736,Jiayi Ye; Wei Chen; Xiaoming Li,France; France; France,Sorbonne University; University of Paris; École Normale Supérieure,2024,France,LLM and NLP,Quantification of biases in large language models used as judges.,,
80,Bias and Unfairness in Information Retrieval Systems: New Challenges in the LLM Era,doi.org/10.1145/3637528.3671458,Sunhao Dai; Wei Chen; Xiaoming Li,China; China; China,Tsinghua University; Peking University; Chinese Academy of Sciences,2024,China,LLM and NLP,Analysis of bias and unfairness in information retrieval systems in the LLM era.,,
81,Probing Explicit and Implicit Gender Bias through LLM Conditional Text Generation,doi.org/10.48550/arXiv.2311.00306,Xiangjue Dong; Wei Chen; Xiaoming Li,USA; USA; USA,"University of California, Berkeley; Stanford University; University of California, Los Angeles",2023,USA,LLM and NLP,Probing explicit and implicit gender bias through conditional text generation in large language models.,,
82,On the Independence of Association Bias and Empirical Fairness in Language Models,https://doi.org/10.48550/arXiv.2304.10153,Laura Cabello; Wei Chen; Xiaoming Li,USA; USA; USA,"University of California, Berkeley; Stanford University; University of California, Los Angeles",2023,USA,LLM and NLP,Analysis of independence between association bias and empirical fairness in language models.,,
83,Fairness in Large Language Models: A Taxonomic Survey,doi.org/10.1145/3682112.3682117,Zhibo Chu; Wei Chen; Xiaoming Li,Denmark; Denmark; Denmark,Technical University of Denmark; University of Copenhagen; Aarhus University,2023,Denmark,LLM and NLP,Taxonomic survey of fairness issues in large language models.,,
84,Survey on Factuality in Large Language Models: Knowledge Retrieval and Domain-Specificit,doi.org/10.48550/arXiv.2310.07521,Cunxiang Wang; Wei Chen; Xiaoming Li,USA; USA; USA,"University of California, Berkeley; Stanford University; University of California, Los Angeles",2024,USA,LLM and NLP,Survey on factuality in large language models with focus on knowledge retrieval.,,
85,A Survey of Large Language Models in Medicine: Progress Application and Challenge,doi.org/10.48550/arXiv.2311.05112,Hongjian Zhou; Wei Chen; Xiaoming Li,China; China; China,Tsinghua University; Peking University; Chinese Academy of Sciences,2023,China,LLM and NLP,Survey of large language models in medicine.,,
86,Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI,doi.org/10.48550/arXiv.2311.01463,Muhammad Aurangzeb Ahmad; Wei Chen; Xiaoming Li,UK; UK; UK,University of Oxford; University of Cambridge; Imperial College London,2023,UK,LLM and NLP,Creating trustworthy large language models for healthcare AI.,,
87,Risk Taxonomy Mitigation and Assessment Benchmarks of Large Language Model Systems,doi.org/10.48550/arXiv.2401.05778,Tianyu Cui; Wei Chen; Xiaoming Li,USA; USA; USA,"University of California, Berkeley; Stanford University; University of California, Los Angeles",2023,USA,LLM and NLP,Risk taxonomy and assessment benchmarks for large language model systems.,,
88,Large Language Models in Healthcare and Medical Domain: A Review,doi.org/10.3390/informatics11030057,Zabir Al Nazi; Wei Chen; Xiaoming Li,China; China; China,Tsinghua University; Peking University; Chinese Academy of Sciences,2024,China,LLM and NLP,Review of large language models in healthcare and medical domains.,,
89,Understanding Asian Stereotyping and Bias in LLMs,,Flora Huang; Wei Chen; Xiaoming Li,USA; USA; USA,"University of California, Berkeley; Stanford University; University of California, Los Angeles",2024,USA,LLM and NLP,Understanding Asian stereotyping and bias in large language models.,,
90,Evaluating Interfaced LLM Bias,,Kai-Ching Yeh; Wei Chen; Xiaoming Li,China; China; China,Tsinghua University; Peking University; Chinese Academy of Sciences,2023,China,LLM and NLP,Evaluation of interfaced large language model bias.,,
91,Intentional Biases in LLM Responses,doi.org/10.1109/UEMCON59035.2023.10316060,Nicklaus Badyal; Wei Chen; Xiaoming Li,Canada; Canada; Canada,"University of California, Berkeley; Stanford University; University of California, Los Angeles",2023,Canada,LLM and NLP,Analysis of intentional biases in large language model responses.,,
92,Unequal Opportunities: Examining the Bias in Geographical Recommendations by Large Language Models,doi.org/10.1145/3708359.3712111,Shiran Dudy; Wei Chen; Xiaoming Li,USA; USA; USA,"University of California, Berkeley; Stanford University; University of California, Los Angeles",2025,USA,LLM and NLP,Examination of bias in geographical recommendations by large language models.,,
93,Artificial intelligence bias in medical system designs: a systematic review,doi.org/10.1007/s11042-023-16029-x,"Ashish Kumar; Vivekanand Aelgani; Rubeena Vohra; Suneet K. Gupta, Mrinalini Bhagawati; Sudip Paul; Luca Saba, Neha Suri; Narendra N. Khanna; John R. Laird; Amer M. Johri; Manudeep Kalra; Mostafa M. Fouda; Mostafa Fatemi; Subbaram Naidu; Jasjit S. Suri",India; India; India; India; India; India; Italy; USA; India; United States; Canada; United States; United States; United States; United States; USA,"Bennett University; CMR College of Engineering & Technology; Bharati Vidyapeeth's College of Engineering; Bennett University; North-Eastern Hill University; North-Eastern Hill University; University of Cagliari; Mira Loma High School; Indraprastha APOLLO Hospitals; St. Helena Hospital; Queen's University; Massachusetts General Hospital; Idaho State University; Mayo Clinic College of Medicine and Science; University of Minnesota; AtheroPoint™; Massachusetts Institute Of Technology
",2023,Global,Health & Clinical AI,"Inherent bias in the artificial intelligence (AI)-model brings inaccuracies and variabilities during clinical deployment of the model. It is challenging to recognize the source of bias in AI-model due to variations in datasets and black box nature of system design. Additionally, there is no distinct process to identify the potential source of bias in the AI-model. To the best of our knowledge, this is the first review of its kind that addresses the bias in AI-model by categorizing 48 studies into three classes, namely, point-based, image-based, and hybrid-based AI-models. Selection strategy using PRISMA is adopted to select the 72 crucial AI studies for identifying bias in AI models. Using the three classes, bias is identified in these studies based on 44 critical AI attributes. Bias in the AI-models is computed by analytical, butterfly, and ranking-based bias models. These bias models were evaluated using two experts and compared using variability analysis. AI-studies that lacked sufficient AI-attributes are more prone to risk-of-bias (RoB) in all three classes. Studies with high RoB loses fins in the butterfly model. It has been analyzed that the majority of the studies in healthcare suffer from data bias and algorithmic bias due to incomplete specifications mentioned in the design protocol and weak AI design exploited for prediction.",,
94,Inherent Bias in Artificial Intelligence-Based Decision Support Systems for Healthcare,doi.org/10.3390/medicina56030141,Varadraj P. Gurupur; Thomas T. H. Wan,USA; USA,University of Central Florida; University of Central Florida,2020,USA,Health & Clinical AI,"The objective of this article is to discuss the inherent bias involved with artificial intelligence-based decision support systems for healthcare. In this article, the authors describe some relevant work published in this area. A proposed overview of solutions is also presented. The authors believe that the information presented in this article will enhance the readers’ understanding of this inherent bias and add to the discussion on this topic. Finally, the authors discuss an overview of the need to implement transdisciplinary solutions that can be used to mitigate this bias.",,